{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_types_mapping_filename = \"/config/types_mapping.json\"\n",
    "data_filename_import = \"/data/input/users/load.csv\"\n",
    "data_filename_parquet_product_export = \"/data/output/product_export_spark.parquet\"\n",
    "data_filename_csv_product_export = \"/data/output/product_export_spark.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_sort_values = \"update_date\"\n",
    "column_drop_duplicates = \"id\"\n",
    "time_format = \"yyyy-MM-dd' 'HH:mm:ss.SSSSSS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.context import SQLContext\n",
    "\n",
    "spark = SparkSession.builder.appName(\"ImportExportCSVToParquet\").master(\"spark://spark:7077\").getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sqlCtx = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.sql.types import *\n",
    "# schema = StructType([\n",
    "#    StructField(\"id\", IntegerType(), True),\n",
    "#    StructField(\"name\", StringType(), True),\n",
    "#    StructField(\"email\", StringType(), True),\n",
    "#    StructField(\"phone\", StringType(), True),\n",
    "#    StructField(\"address\", StringType(), True),\n",
    "#    StructField(\"age\", IntegerType(), True),\n",
    "#    StructField(\"create_date\", StringType(), True),\n",
    "#    StructField(\"update_date\", StringType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', 'bigint'),\n",
       " ('name', 'string'),\n",
       " ('email', 'string'),\n",
       " ('phone', 'string'),\n",
       " ('address', 'string'),\n",
       " ('age', 'bigint'),\n",
       " ('create_date', 'string'),\n",
       " ('update_date', 'string')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_row_data = pd.read_csv(data_filename_import)\n",
    "# sdf_row_data = sqlCtx.createDataFrame(df_row_data,schema)\n",
    "sdf_row_data = sqlCtx.createDataFrame(df_row_data)\n",
    "sdf_row_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_timestamp, desc\n",
    "\n",
    "sdf_conveted_column_to_sort_data = sdf_row_data.withColumn(column_sort_values, to_timestamp(sdf_row_data[column_sort_values], time_format))\n",
    "sdf_sorted_data = sdf_conveted_column_to_sort_data.orderBy(desc(column_sort_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_deduplicate_data = sdf_sorted_data.drop_duplicates([column_drop_duplicates])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(id=1, name='david.lynch@cognitivo.ai', email='David Lynch', phone='(11) 99999-9999', address='Mulholland Drive, Los Angeles, CA, US', age=72, create_date='2018-03-03 18:47:01.954752', update_date=datetime.datetime(2018, 5, 23, 10, 13, 59, 594752))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf_deduplicate_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'bigint', 'name': 'string', 'email': 'string', 'phone': 'string', 'address': 'string', 'age': 'integer', 'create_date': 'timestamp', 'update_date': 'timestamp'}\n"
     ]
    }
   ],
   "source": [
    "# carregamento metodo para mapeamento de tipos\n",
    "from load_mapping_types import load_mapping_types\n",
    "\n",
    "types_mapping_dict = load_mapping_types(config_types_mapping_filename, sdf_deduplicate_data.dtypes, False)\n",
    "print(types_mapping_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "def convert_type_data_frame(df):\n",
    "    return df.select(*(col(k).cast(types_mapping_dict[k]).alias(k) for k in types_mapping_dict.keys()))\n",
    "\n",
    "df_converted_type_data = sdf_deduplicate_data.transform(convert_type_data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', 'bigint'),\n",
       " ('name', 'string'),\n",
       " ('email', 'string'),\n",
       " ('phone', 'string'),\n",
       " ('address', 'string'),\n",
       " ('age', 'int'),\n",
       " ('create_date', 'timestamp'),\n",
       " ('update_date', 'timestamp')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_converted_type_data.dtypes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_converted_type_data.toPandas().to_csv(data_filename_csv_product_export,index=False)\n",
    "df_converted_type_data.toPandas().to_parquet(data_filename_parquet_product_export,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                      int64\n",
       "name                   object\n",
       "email                  object\n",
       "phone                  object\n",
       "address                object\n",
       "age                     int32\n",
       "create_date    datetime64[ns]\n",
       "update_date    datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_converted_type_data.toPandas().dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
